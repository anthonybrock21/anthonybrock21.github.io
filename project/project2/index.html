<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Anthony Bruccoliere" />
    
    <link rel="shortcut icon" type="image/x-icon" href="../../img/favicon.ico">
    <title>Project 2: Modeling, Testing, and Predicting</title>
    <meta name="generator" content="Hugo 0.83.1" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="../../css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="../../"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="../../post/">BLOG</a></li>
        
        <li><a href="../../projects/">PROJECTS</a></li>
        
        <li><a href="../../resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="../../project/project2/">Project 2: Modeling, Testing, and Predicting</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         January 1, 0001 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              


<div id="anthony-bruccoliere-adb3778" class="section level2">
<h2>Anthony Bruccoliere (adb3778)</h2>
<pre class="r"><code>library(sandwich)
library(lmtest)
library(plotROC)
library(pROC)
library(glmnet)
library(dplyr)
election&lt;-read.csv(&quot;election_turnout.csv&quot;)
glimpse(election)</code></pre>
<pre><code>## Rows: 51
## Columns: 11
## $ X &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,
15, 16, 17, 18, 19, 20, 21, 22, …
## $ year &lt;int&gt; 2016, 2016, 2016, 2016, 2016, 2016, 2016,
2016, 2016, 2016, 2016, 2016, 2016, 2…
## $ state &lt;fct&gt; Alabama, Alaska, Arizona, Arkansas,
California, Colorado, Connecticut, Delaware…
## $ region &lt;fct&gt; South, West, West, South, West, West,
Northeast, South, South, South, South, We…
## $ division &lt;fct&gt; East South Central, Pacific, Mountain,
West South Central, Pacific, Mountain, N…
## $ turnoutho &lt;dbl&gt; 59.0, 61.3, 55.0, 52.8, 56.7, 70.1,
65.2, 64.4, 60.9, 64.6, 59.2, 42.2, 59.1, 6…
## $ perhsed &lt;dbl&gt; 84.3, 92.1, 86.0, 84.8, 81.8, 90.7,
89.9, 88.4, 89.3, 86.9, 85.4, 91.0, 89.5, 8…
## $ percoled &lt;dbl&gt; 23.5, 28.0, 27.5, 21.1, 31.4, 38.1,
37.6, 30.0, 54.6, 27.3, 28.8, 30.8, 25.9, 3…
## $ gdppercap &lt;int&gt; 42663, 81801, 43269, 41129, 61924,
58009, 72331, 69930, 181185, 42595, 48574, 5…
## $ ss &lt;int&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,
1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0…
## $ trumpw &lt;int&gt; 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,
1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1…</code></pre>
<pre class="r"><code>elec&lt;-election %&gt;% select(region,division,turnoutho,gdppercap,trumpw)
elec2&lt;-elec %&gt;% mutate(Won_By=recode(trumpw,&#39;0&#39;=&#39;Clinton&#39;,&#39;1&#39;=&#39;Trump&#39;))
gdp_c&lt;-elec$gdppercap-mean(elec$gdppercap)
glimpse(elec)</code></pre>
<pre><code>## Rows: 51
## Columns: 5
## $ region &lt;fct&gt; South, West, West, South, West, West,
Northeast, South, South, South, South, We…
## $ division &lt;fct&gt; East South Central, Pacific, Mountain,
West South Central, Pacific, Mountain, N…
## $ turnoutho &lt;dbl&gt; 59.0, 61.3, 55.0, 52.8, 56.7, 70.1,
65.2, 64.4, 60.9, 64.6, 59.2, 42.2, 59.1, 6…
## $ gdppercap &lt;int&gt; 42663, 81801, 43269, 41129, 61924,
58009, 72331, 69930, 181185, 42595, 48574, 5…
## $ trumpw &lt;int&gt; 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,
1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1…</code></pre>
<pre class="r"><code>class_diag&lt;-function(probs,truth){
  
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}</code></pre>
<p>#Introduction
For this project, I will be analyzing data taken from the 2016 election. This dataset had 51 observations, all states and DC, and 11 variables. I formed a separate dataset containing the variables: region, division, turnout rate, gdp per capita, and whether Trump won that state. I omitted the state identifier because that variable would interfere with later tests assessing predictor variables. I also omitted other variables that weren’t of interest or were redundant. This project will evaluate the variables and their interactions through several statistical tests.
#Manova</p>
<pre class="r"><code>man1 &lt;- manova(cbind(turnoutho, gdppercap)~division, data=elec)
summary(man1)</code></pre>
<pre><code>##           Df  Pillai approx F num Df den Df Pr(&gt;F)
## division   8 0.41563   1.3773     16     84 0.1732
## Residuals 42</code></pre>
<pre class="r"><code>summary.aov(man1)</code></pre>
<pre><code>## Response turnoutho :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## division 8 566.21 70.776 2.2782 0.04005 *
## Residuals 42 1304.80 31.067
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response gdppercap :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## division 8 2.6617e+09 332717365 0.7457 0.6512
## Residuals 42 1.8740e+10 446202237</code></pre>
<pre class="r"><code>elec %&gt;% group_by(trumpw) %&gt;% summarize(mean(turnoutho),mean(gdppercap))</code></pre>
<pre><code>## # A tibble: 2 x 3
##   trumpw `mean(turnoutho)` `mean(gdppercap)`
##    &lt;int&gt;             &lt;dbl&gt;             &lt;dbl&gt;
## 1      0              63.1            64143.
## 2      1              59.3            49935.</code></pre>
<pre class="r"><code>pairwise.t.test(elec$turnoutho,elec$division,p.adj=&quot;none&quot;)-&gt;output

output</code></pre>
<pre><code>##
## Pairwise comparisons using t tests with pooled SD
##
## data: elec$turnoutho and elec$division
##
## East North Central East South Central Middle Atlantic
Mountain New England
## East South Central 0.0707 - - - -
## Middle Atlantic 0.7035 0.2137 - - -
## Mountain 0.2449 0.3557 0.5652 - -
## New England 0.3626 0.0079 0.2430 0.0279 -
## Pacific 0.1824 0.5674 0.4334 0.7468 0.0243
## South Atlantic 0.6159 0.1168 0.9976 0.4262 0.1188
## West North Central 0.8934 0.0408 0.6058 0.1540 0.3947
## West South Central 0.0225 0.6278 0.0937 0.1416 0.0018
## Pacific South Atlantic West North Central
## East South Central - - -
## Middle Atlantic - - -
## Mountain - - -
## New England - - -
## Pacific - - -
## South Atlantic 0.3079 - -
## West North Central 0.1172 0.4780 -
## West South Central 0.2814 0.0352 0.0110
##
## P value adjustment method: none</code></pre>
<pre class="r"><code>output$p.value*31</code></pre>
<pre><code>## East North Central East South Central Middle Atlantic
Mountain New England
## East South Central 2.1903452 NA NA NA NA
## Middle Atlantic 21.8075719 6.6244203 NA NA NA
## Mountain 7.5914524 11.0269463 17.521436 NA NA
## New England 11.2400330 0.2440021 7.534433 0.8662397 NA
## Pacific 5.6529736 17.5908848 13.433961 23.1520592
0.75319319
## South Atlantic 19.0943541 3.6199919 30.926478 13.2110248
3.68283516
## West North Central 27.6953854 1.2636230 18.779883
4.7750432 12.23561650
## West South Central 0.6967767 19.4614518 2.906248
4.3911135 0.05693943
## Pacific South Atlantic West North Central
## East South Central NA NA NA
## Middle Atlantic NA NA NA
## Mountain NA NA NA
## New England NA NA NA
## Pacific NA NA NA
## South Atlantic 9.544938 NA NA
## West North Central 3.633833 14.816991 NA
## West South Central 8.723484 1.091718 0.3397194</code></pre>
<pre class="r"><code>1-.95^31</code></pre>
<pre><code>## [1] 0.7960932</code></pre>
<pre class="r"><code>.05/31</code></pre>
<pre><code>## [1] 0.001612903</code></pre>
<p>I ran a MANOVA test to determine the effect of the division on election turnout and state gdp. The initial MANOVA showed no significant interaction with the varaibles. However, after I ran the univariate ANOVAs, there was a significant interaction between divisions and turnout rate in the elections. To explore this, I ran a post hoc t test on the divisions and adjusted for error. The tests showed no significance among divisions, but the New England and West South Central divisions were the closest to showing a significant effect. I performed a total of 31 tests, so there is a 79.6% chance that there is at least one type 1 error. The bonferroni correction is .0016. These tests likely failed to show significance because the divisions and states within them are likely large enough to mask outliers. Because this data is from only from one year, this dataset likely fails most assumptions. There also doesn’t appear to be any clear linear relationships among the dependent variables.</p>
<p>#Randomization</p>
<pre class="r"><code>elec %&gt;% group_by(trumpw) %&gt;% summarize(mean(turnoutho),mean(gdppercap))</code></pre>
<pre><code>## # A tibble: 2 x 3
##   trumpw `mean(turnoutho)` `mean(gdppercap)`
##    &lt;int&gt;             &lt;dbl&gt;             &lt;dbl&gt;
## 1      0              63.1            64143.
## 2      1              59.3            49935.</code></pre>
<pre class="r"><code>clintgdps&lt;-c(61924,58009,72331,69930,181185,55598,59472,41477,60097,69705,60256,48639,53834,64070,41551,72965,56009,53321,47520,56891,62213)
trumpgdps&lt;-c(42663,81801,43269,41129,42595,48574,39398,49328,52807,50218,41586,54159,46585,35717,47209,44308,59175,50159,70926,51052,46298,52925,40212,51902,46531,59994,48965,38567,51456,68536)
gdps&lt;-data.frame(candidate=c(rep(&quot;Clinton&quot;,21),rep(&quot;Trump&quot;,30)),gdp=c(clintgdps,trumpgdps))
glimpse(gdps)</code></pre>
<pre><code>## Rows: 51
## Columns: 2
## $ candidate &lt;fct&gt; Clinton, Clinton, Clinton, Clinton,
Clinton, Clinton, Clinton, Clinton, Clinton…
## $ gdp &lt;dbl&gt; 61924, 58009, 72331, 69930, 181185, 55598,
59472, 41477, 60097, 69705, 60256, 4…</code></pre>
<pre class="r"><code>gdps %&gt;% ggplot(aes(gdp,fill=candidate))+geom_histogram(bins=10)+facet_wrap(~candidate,ncol = 2)+theme(legend.position=&quot;none&quot;)+scale_color_manual(breaks = c(&quot;Trump&quot;, &quot;Clinton&quot;),values=c(&quot;red&quot;, &quot;blue&quot;))</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>gdps %&gt;% group_by(candidate) %&gt;% summarize(means=mean(gdp)) %&gt;% summarize(mean_diff=diff(means)) #clinton higher mean</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_diff
##       &lt;dbl&gt;
## 1   -14208.</code></pre>
<pre class="r"><code>permR&lt;-data.frame(candidate=gdps$candidate,gdp=sample(gdps$gdp))
permR %&gt;% group_by(candidate) %&gt;% summarize(means=mean(gdp)) %&gt;% summarize(mean_diff=diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_diff
##       &lt;dbl&gt;
## 1     6722.</code></pre>
<pre class="r"><code>dist_perm&lt;-vector()
for (i in 1:5000) {
  new&lt;-data.frame(gdp=sample(gdps$gdp),candidate=gdps$candidate)
  dist_perm[i]&lt;-mean(new[new$candidate==&quot;Clinton&quot;,]$gdp)-mean(new[new$candidate==&quot;Trump&quot;,]$gdp)}
{hist(dist_perm,main=&quot;&quot;,ylab=&quot;&quot;); abline(v = -14207.91,col=&quot;red&quot;)}</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-5-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>mean(dist_perm&gt;14207.91)</code></pre>
<pre><code>## [1] 0.001</code></pre>
<pre class="r"><code>mean(-14207.91&gt;dist_perm)</code></pre>
<pre><code>## [1] 2e-04</code></pre>
<pre class="r"><code>t.test(data=elec2,gdp_c~Won_By,var.eq=T)</code></pre>
<pre><code>##
## Two Sample t-test
##
## data: gdp_c by Won_By
## t = 2.542, df = 49, p-value = 0.01423
## alternative hypothesis: true difference in means is not
equal to 0
## 95 percent confidence interval:
## 2976.076 25439.752
## sample estimates:
## mean in group Clinton mean in group Trump
## 8357.597 -5850.318</code></pre>
<p>I performed a randomization test on the GDPs of the states to explore the differences between candidates. The null hypothesis was that average GDPs were the same for both Trump and Clinton states and the alternative hypothesis was that the average GDPs were different for Trump and Clinton sates. I calculated the mean difference to be 14207.91 with Clinton states having the higher GDP. I then randomized the data and created a histogram to visualize the distribution. I added a red line at the observed difference and as you can see it is at the far extreme of the histogram. There were no randomized differences that extreme, so we can reject the null that the average GDPs were the same for both Trump and Clinton states. There is a difference between the average GDPs of Trump and Clinton states and a t-test confirms this with a p value of 0.014.</p>
<p>#Linear Regression</p>
<pre class="r"><code>elec$gdp_c&lt;-elec$gdppercap-mean(elec$gdppercap)
elec$turnout_c&lt;-elec$turnoutho-mean(elec$turnoutho)
elec2&lt;-elec %&gt;% mutate(Won_By=recode(trumpw,&#39;0&#39;=&#39;Clinton&#39;,&#39;1&#39;=&#39;Trump&#39;))
linfit&lt;-lm(gdp_c~turnout_c*Won_By,data = elec2)
summary(linfit)</code></pre>
<pre><code>##
## Call:
## lm(formula = gdp_c ~ turnout_c * Won_By, data = elec2)
##
## Residuals:
## Min 1Q Median 3Q Max
## -23923 -7366 -3244 1023 116694
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 8718.5 4574.6 1.906 0.0628 .
## turnout_c -161.1 631.0 -0.255 0.7996
## Won_ByTrump -13725.6 5965.4 -2.301 0.0259 *
## turnout_c:Won_ByTrump 698.8 985.5 0.709 0.4818
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 19940 on 47 degrees of freedom
## Multiple R-squared: 0.1271, Adjusted R-squared: 0.07137
## F-statistic: 2.281 on 3 and 47 DF, p-value: 0.09145</code></pre>
<pre class="r"><code>t.test(data=elec2,gdp_c~Won_By,var.eq=T)</code></pre>
<pre><code>##
## Two Sample t-test
##
## data: gdp_c by Won_By
## t = 2.542, df = 49, p-value = 0.01423
## alternative hypothesis: true difference in means is not
equal to 0
## 95 percent confidence interval:
## 2976.076 25439.752
## sample estimates:
## mean in group Clinton mean in group Trump
## 8357.597 -5850.318</code></pre>
<pre class="r"><code>ggplot(elec2,aes(gdp_c,turnout_c,group=Won_By))+
  geom_point(aes(color=Won_By),alpha=.5)+
  geom_smooth(method =&quot;lm&quot;,fullrange=T,aes(color=Won_By))+theme(legend.position =&quot;top&quot;)+
  scale_color_manual(breaks = c(&quot;Trump&quot;, &quot;Clinton&quot;),values=c(&quot;red&quot;, &quot;blue&quot;))</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>(sum((elec$gdp_c-mean(elec$gdp_c))^2)-sum(linfit$residuals^2))/sum((elec$gdp_c-mean(elec$gdp_c))^2)</code></pre>
<pre><code>## [1] 0.1270915</code></pre>
<p>For the linear regression, i explored the interaction between turnout rate and who won the state on the states GDP. The coefficients show an intercept of 8718.5, a decrease of 161.1 for an increase of turnout rate, a decrease of 13,725.6 if won by Trump, and the slope for turnout on gdp is 698.8 higher for Trump states. Only the coefficient for the Won_By predictor was significant in predicting GDP. I plotted the model and as you can see there is not much separation between the candidates. This model also only explains 12.7% of the variation.</p>
<pre class="r"><code>resids&lt;-linfit$residuals
fitvals&lt;-linfit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color=&#39;red&#39;) </code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot()+geom_histogram(aes(resids), bins=25)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-7-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot()+geom_qq(aes(sample=resids))+geom_qq_line(aes(sample=resids))</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-7-3.png" width="768" style="display: block; margin: auto;" />
I plotted the data to test for homoskedasticity, normality, and linearity. In the first plot it appears that the data is fairly linear and exhibits homoskedasticity. In the second plot, it appears that the plot is mostly normal with a couple outliers. In the third plot, most of the points fall along the line so the data is mostly linear. Points do stray at the extremes.</p>
<pre class="r"><code>linfit2&lt;-lm(gdp_c~turnout_c*Won_By,data = elec2)
bptest(linfit2) #fail to reject null</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  linfit2
## BP = 1.8902, df = 3, p-value = 0.5955</code></pre>
<pre class="r"><code>summary(linfit2)$coef[,1:2]</code></pre>
<pre><code>##                          Estimate Std. Error
## (Intercept)             8718.5082  4574.5928
## turnout_c               -161.0971   631.0360
## Won_ByTrump           -13725.6434  5965.4069
## turnout_c:Won_ByTrump    698.7603   985.5363</code></pre>
<pre class="r"><code>coeftest(linfit2, vcov = vcovHC(linfit2))[,1:2]</code></pre>
<pre><code>##                          Estimate Std. Error
## (Intercept)             8718.5082  7318.5708
## turnout_c               -161.0971   643.4842
## Won_ByTrump           -13725.6434  7569.0851
## turnout_c:Won_ByTrump    698.7603   704.3033</code></pre>
<p>The results of the bp test show a p-value of 0.596, so we fail to reject the null and conclude that the data is homoskedastic. After the robust standard error was performed, the standard error for the intercept, turnout, and Won_By all increased while the standard error for the turnout:won_by interaction decreased.
#Bootstrapping</p>
<pre class="r"><code>set.seed(1234)
lm(gdp_c~turnout_c*Won_By,data = elec2) %&gt;% summary</code></pre>
<pre><code>##
## Call:
## lm(formula = gdp_c ~ turnout_c * Won_By, data = elec2)
##
## Residuals:
## Min 1Q Median 3Q Max
## -23923 -7366 -3244 1023 116694
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 8718.5 4574.6 1.906 0.0628 .
## turnout_c -161.1 631.0 -0.255 0.7996
## Won_ByTrump -13725.6 5965.4 -2.301 0.0259 *
## turnout_c:Won_ByTrump 698.8 985.5 0.709 0.4818
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 19940 on 47 degrees of freedom
## Multiple R-squared: 0.1271, Adjusted R-squared: 0.07137
## F-statistic: 2.281 on 3 and 47 DF, p-value: 0.09145</code></pre>
<pre class="r"><code>samp_dist&lt;-replicate(5000,{
  boot_dat&lt;-sample_frac(elec2,replace = T)
  bootfit&lt;-lm(gdp_c~turnout_c*Won_By,data = boot_dat)
  coef(bootfit)
})
samp_dist %&gt;% t %&gt;% as.data.frame %&gt;% summarise_all(sd)</code></pre>
<pre><code>##   (Intercept) turnout_c Won_ByTrump turnout_c:Won_ByTrump
## 1    8074.509   849.087    8284.752              892.9009</code></pre>
<p>The bootstrapped SEs are: 8212.1 for the intercept, 860.8 for the turnout, 8401.6 for trump states, and 911.1 for the interaction. These errors are all a bit higher than the robust SEs. The interaction is still slightly lower than the first SE. Because these standard errors are greater, these tests support the conclusion to fail to reject the null. The original SEs were 4574.6 for the intercept, 631.0 for the turnout, 5965.4 for the trump states, and 985.5 for the interaction.</p>
<p>#logistic regression</p>
<pre class="r"><code>logfit&lt;-glm(trumpw~gdppercap+turnoutho,data=elec,family=&quot;binomial&quot;)
coeftest(logfit)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) 1.0059e+01 3.8216e+00 2.6322 0.008482 **
## gdppercap -7.5566e-05 3.4252e-05 -2.2062 0.027370 *
## turnoutho -9.0880e-02 5.8498e-02 -1.5536 0.120289
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coeftest(logfit))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##               Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) 2.3374e+04 4.5677e+01 13.9049    1.009
## gdppercap   9.9992e-01 1.0000e+00  0.1101    1.028
## turnoutho   9.1313e-01 1.0602e+00  0.2115    1.128</code></pre>
<pre class="r"><code>prob&lt;-predict(logfit,type = &quot;response&quot;)
table(predict=as.numeric(prob&gt;.5),truth=elec$trumpw)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict  0  1 Sum
##     0   14  6  20
##     1    7 24  31
##     Sum 21 30  51</code></pre>
<pre class="r"><code>(14+24)/51 #Accuracy</code></pre>
<pre><code>## [1] 0.745098</code></pre>
<pre class="r"><code>(24/30) #Sensitivity</code></pre>
<pre><code>## [1] 0.8</code></pre>
<pre class="r"><code>(14/21) #Specificity</code></pre>
<pre><code>## [1] 0.6666667</code></pre>
<pre class="r"><code>class_diag(prob,elec$trumpw)</code></pre>
<pre><code>##        acc sens      spec       ppv       auc
## 1 0.745098  0.8 0.6666667 0.7741935 0.7761905</code></pre>
<pre class="r"><code>elec$logit&lt;-predict(logfit,type=&quot;link&quot;)
ggplot(elec,aes(logit, fill=as.factor(trumpw)))+geom_density(alpha=.3)+
  theme(legend.position=c(.63,.85))+geom_vline(xintercept=0)+xlab(&quot;predictor (logit)&quot;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-10-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ROCplot&lt;-ggplot(elec)+geom_roc(aes(d=trumpw,m=prob), n.cuts=0) 
ROCplot</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-10-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.7761905</code></pre>
<p>The coefficient estimates for my logistical regression are: 1.0059e+01 for the intercept, -7.5566e-05 for the GDP, and -9.0880e-02 for the turnout. Only the intercept and GDP were found to be significant. We can reject the null for GDPs ability to predict trump states but can’t reject the null for turnout rates ability to do the same. The accuracy, sensitivity, specificity, presicion and area under the curve were calculated to be .745, .8, .6667, .774, and .776, respectively. This model will more likely than not predict correctly. The first plot depicts the predicted separation as compared to the actual. There appears to be quite a bit of error with many states improperly predicted. The ROC plot suggests the model predictions to be fair with an AUC of .776.
#logistic regression 2 with LASSO</p>
<pre class="r"><code>elec3&lt;-elec %&gt;% select(-gdp_c,-turnout_c,-logit)
logfit2&lt;-glm(trumpw~.,data=elec3, family=&quot;binomial&quot;)
summary(logfit2)</code></pre>
<pre><code>##
## Call:
## glm(formula = trumpw ~ ., family = &quot;binomial&quot;, data =
elec3)
##
## Deviance Residuals:
## Min 1Q Median 3Q Max
## -1.79199 -0.52846 0.00009 0.61674 2.50324
##
## Coefficients: (3 not defined because of singularities)
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) 9.386e+00 5.066e+00 1.853 0.0639 .
## regionNortheast -2.064e+01 4.223e+03 -0.005 0.9961
## regionSouth 1.752e+01 5.242e+03 0.003 0.9973
## regionWest -2.658e+00 1.880e+00 -1.414 0.1574
## divisionEast South Central -5.262e-01 7.477e+03 0.000
0.9999
## divisionMiddle Atlantic 1.915e+01 4.223e+03 0.005 0.9964
## divisionMountain 1.347e+00 1.615e+00 0.834 0.4043
## divisionNew England NA NA NA NA
## divisionPacific NA NA NA NA
## divisionSouth Atlantic -1.848e+01 5.242e+03 -0.004
0.9972
## divisionWest North Central 8.490e-01 1.620e+00 0.524
0.6003
## divisionWest South Central NA NA NA NA
## turnoutho -7.214e-02 7.671e-02 -0.940 0.3470
## gdppercap -6.595e-05 5.043e-05 -1.308 0.1910
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## (Dispersion parameter for binomial family taken to be 1)
##
## Null deviance: 69.104 on 50 degrees of freedom
## Residual deviance: 36.809 on 40 degrees of freedom
## AIC: 58.809
##
## Number of Fisher Scoring iterations: 18</code></pre>
<pre class="r"><code>prob3&lt;-predict(logfit2,type = &quot;response&quot;)
class_diag(prob3,elec$trumpw)</code></pre>
<pre><code>##         acc sens      spec     ppv       auc
## 1 0.8431373  0.9 0.7619048 0.84375 0.9253968</code></pre>
<pre class="r"><code>set.seed(1234)
k=10 
data&lt;-elec3[sample(nrow(elec3)),] 
folds&lt;-cut(seq(1:nrow(elec3)),breaks=k,labels=F) 
diags2&lt;-NULL
for(i in 1:k){
train&lt;-data[folds!=i,]
test&lt;-data[folds==i,]
truth&lt;-test$trumpw 
fitCV&lt;-glm(trumpw~.,data=train,family=&quot;binomial&quot;)
probs&lt;-predict(fitCV,newdata = test,type=&quot;response&quot;)
diags2&lt;-rbind(diags2,class_diag(probs,truth))
}
summarize_all(diags2,mean)</code></pre>
<pre><code>##   acc      sens spec   ppv   auc
## 1 0.8 0.9166667 0.75 0.815 0.825</code></pre>
<pre class="r"><code>y&lt;-as.matrix(elec3$trumpw) #grab response
x&lt;-model.matrix(trumpw~.,data=elec3)[,-1] #grab predictors
x&lt;-scale(x)
cv&lt;-cv.glmnet(x,y)
lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                                     s0
## (Intercept)                 0.36308639
## regionNortheast            -0.25594798
## regionSouth                 .         
## regionWest                  .         
## divisionEast South Central  .         
## divisionMiddle Atlantic     .         
## divisionMountain            .         
## divisionNew England        -0.17142869
## divisionPacific            -0.04988352
## divisionSouth Atlantic      .         
## divisionWest North Central  .         
## divisionWest South Central  .         
## turnoutho                   .         
## gdppercap                  -0.14908070</code></pre>
<pre class="r"><code>Lassores&lt;-elec3 %&gt;% mutate(Northeast=ifelse(region==&quot;Northeast&quot;,1,0), &quot;New England&quot; = ifelse(division==&quot;New England&quot;,1,0),&quot;Pacific&quot; = ifelse(division==&quot;Pacific&quot;,1,0)) %&gt;% select(Northeast,&quot;New England&quot;,Pacific, gdppercap, trumpw)

set.seed(1234)
k=10 
data&lt;-Lassores[sample(nrow(Lassores)),] 
folds&lt;-cut(seq(1:nrow(Lassores)),breaks=k,labels=F) 
diags3&lt;-NULL
for(i in 1:k){
train&lt;-data[folds!=i,]
test&lt;-data[folds==i,]
truth&lt;-test$trumpw 
fitCV&lt;-glm(trumpw~.,data=train,family=&quot;binomial&quot;)
probs&lt;-predict(fitCV,newdata = test,type=&quot;response&quot;)
diags3&lt;-rbind(diags3,class_diag(probs,truth))
}
summarize_all(diags3,mean)</code></pre>
<pre><code>##    acc      sens  spec       ppv  auc
## 1 0.78 0.9166667 0.675 0.7833333 0.85</code></pre>
<p>Another logistical regression was performed on all variables to predict trump states. The logistical regression showed no significant coefficients. The accuracy, sensitivity, specificity, precision and area under the curve were calculated to be .843, .9, .762, .844, and .925, respectively. All are fairly high predictors and suggest a good to great model. Following a 10 fold cross validation of the same model, the accuracy, sensitivity, specificity, precision and area under the curve were calculated to be .7667, .842, .567, NaN, and .758, respectively. These are all lower values from the original logistical regression. This new AUC suggests a fair model. I then ran a LASSO which showed coeficients for only the northeast region and the new england division. I reran the 10 fold cross validation with only these variables as predictors and recorded the diagnostics. The accuracy, sensitivity, specificity, precision and area under the curve were calculated to be .767, .842, .567, NaN, and .908, respectively. The sensitivity is much higher but the specificity is lower. The AUC with the lasso variables is a bit lower at .675 and suggests a poor model.</p>
</div>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="../../js/docs.min.js"></script>
<script src="../../js/main.js"></script>

<script src="../../js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
